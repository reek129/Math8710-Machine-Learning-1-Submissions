{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc84da9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import shutil\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c4ab426",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# OpenMP: number of parallel threads.\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 256\n",
    "data_transforms = {\n",
    "    \"train\": transforms.Compose(\n",
    "        [\n",
    "            # transforms.RandomResizedCrop(224),     # uncomment for data augmentation\n",
    "            # transforms.RandomHorizontalFlip(),     # uncomment for data augmentation\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            # Normalize input channels using mean values and standard deviations of ImageNet.\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    ),\n",
    "    \"test\": transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    ),\n",
    "}\n",
    "\n",
    "data_dir = \"dataset/\"\n",
    "# data_dir = \"data/hymenoptera_data\"\n",
    "image_datasets = {\n",
    "    x if x == \"train\" else \"test\": datasets.ImageFolder(\n",
    "        os.path.join(data_dir, x), data_transforms[x]\n",
    "    )\n",
    "    for x in [\"train\", \"test\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe876156",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = {x: len(image_datasets[x]) for x in [\"train\", \"test\"]}\n",
    "class_names = image_datasets[\"train\"].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d6aa5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dataloader\n",
    "dataloaders = {\n",
    "    x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True)\n",
    "    for x in [\"train\", \"test\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fed73aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs):\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_loss = 10000.0  # Large arbitrary number\n",
    "    best_acc_train = 0.0\n",
    "    best_loss_train = 10000.0  # Large arbitrary number\n",
    "    \n",
    "    print(\"Training started:\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in [\"train\", \"test\"]:\n",
    "            if phase == \"train\":\n",
    "                # Set model to training mode\n",
    "                model.train()\n",
    "            else:\n",
    "                # Set model to evaluate mode\n",
    "                model.eval()\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            n_batches = dataset_sizes[phase] // batch_size\n",
    "            it = 0\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                since_batch = time.time()\n",
    "                batch_size_ = len(inputs)\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "#                 print(labels)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Track/compute gradient and make an optimization step only when training\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "#                     For neurons more than 1 in last layer\n",
    "                    outputs = model(inputs)\n",
    "#                     print(outputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                #     For one neuron in last layer\n",
    "#                     outputs = model(inputs)\n",
    "#                     preds=outputs\n",
    "#                     print(preds)\n",
    "#                     print(outputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Print iteration results\n",
    "                running_loss += loss.item() * batch_size_\n",
    "                batch_corrects = torch.sum(preds == labels.data).item()\n",
    "                running_corrects += batch_corrects\n",
    "                print(\n",
    "                    \"Phase: {} Epoch: {}/{} Iter: {}/{} Batch time: {:.4f}\".format(\n",
    "                        phase,\n",
    "                        epoch + 1,\n",
    "                        num_epochs,\n",
    "                        it + 1,\n",
    "                        n_batches + 1,\n",
    "                        time.time() - since_batch,\n",
    "                    ),\n",
    "                    end=\"\\r\",\n",
    "                    flush=True,\n",
    "                )\n",
    "                it += 1\n",
    "\n",
    "            # Print epoch results\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "            print(\n",
    "                \"Phase: {} Epoch: {}/{} Loss: {:.4f} Acc: {:.4f}        \".format(\n",
    "                    \"train\" if phase == \"train\" else \"test  \",\n",
    "                    epoch + 1,\n",
    "                    num_epochs,\n",
    "                    epoch_loss,\n",
    "                    epoch_acc,\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # Check if this is the best model wrt previous epochs\n",
    "            if phase == \"test\" and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                torch.save(copy.deepcopy(model.state_dict()),'dogsCatModel.pth')\n",
    "            if phase == \"test\" and epoch_loss < best_loss:\n",
    "                best_loss = epoch_loss\n",
    "            if phase == \"train\" and epoch_acc > best_acc_train:\n",
    "                best_acc_train = epoch_acc\n",
    "            if phase == \"train\" and epoch_loss < best_loss_train:\n",
    "                best_loss_train = epoch_loss\n",
    "\n",
    "            # Update learning rate\n",
    "            if phase == \"train\":\n",
    "                scheduler.step()\n",
    "\n",
    "    # Print final results\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    time_elapsed = time.time() - since\n",
    "    print(\n",
    "        \"Training completed in {:.0f}m {:.0f}s\".format(time_elapsed // 60, time_elapsed % 60)\n",
    "    )\n",
    "    print(\"Best test loss: {:.4f} | Best test accuracy: {:.4f}\".format(best_loss, best_acc))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca7ede53",
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 0.0004   \n",
    "gamma_lr_scheduler = 0.1\n",
    "\n",
    "class ClassicalTransferLearningModel(nn.Module):\n",
    "    def __init__(self,num_of_features):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(num_of_features,2)\n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax= nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3bee0ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "199876fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_classical = torchvision.models.resnet152(pretrained=True)\n",
    "\n",
    "for param in model_classical.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_ftrs = model_classical.fc.in_features\n",
    "model_classical.fc = ClassicalTransferLearningModel(num_ftrs)\n",
    "model_classical = model_classical.to(device)\n",
    "\n",
    "criterion_classical = nn.CrossEntropyLoss()\n",
    "optimizer_classical = optim.Adam(model_classical.fc.parameters(),lr=step)\n",
    "exp_lr_scheduler_classical = lr_scheduler.StepLR(\n",
    "    optimizer_classical, step_size=10, gamma=gamma_lr_scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a9a3160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started:\n",
      "Phase: train Epoch: 1/5 Loss: 0.4868 Acc: 0.9093        \n",
      "Phase: test   Epoch: 1/5 Loss: 0.3810 Acc: 0.9815        \n",
      "Phase: train Epoch: 2/5 Loss: 0.3685 Acc: 0.9782        \n",
      "Phase: test   Epoch: 2/5 Loss: 0.3547 Acc: 0.9880        \n",
      "Phase: train Epoch: 3/5 Loss: 0.3534 Acc: 0.9816        \n",
      "Phase: test   Epoch: 3/5 Loss: 0.3474 Acc: 0.9840        \n",
      "Phase: train Epoch: 4/5 Loss: 0.3469 Acc: 0.9835        \n",
      "Phase: test   Epoch: 4/5 Loss: 0.3404 Acc: 0.9885        \n",
      "Phase: train Epoch: 5/5 Loss: 0.3421 Acc: 0.9848        \n",
      "Phase: test   Epoch: 5/5 Loss: 0.3375 Acc: 0.9885        \n",
      "Training completed in 210m 13s\n",
      "Best test loss: 0.3375 | Best test accuracy: 0.9885\n"
     ]
    }
   ],
   "source": [
    "model_classical = train_model(model_classical,criterion_classical,optimizer_classical,exp_lr_scheduler_classical,num_epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83e5166",
   "metadata": {},
   "source": [
    "# Testing the dogsAndCats.pth model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7bf98b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model):\n",
    "    since = time.time()\n",
    "    print(\"Validation started:\")\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    \n",
    "    running_corrects_test=0\n",
    "\n",
    "    batch_corrects_test=0\n",
    "    phase = \"test\"\n",
    "\n",
    "    n_batches = dataset_sizes[phase]\n",
    "    it=0\n",
    "\n",
    "    for inputs,labels in dataloaders[phase]:\n",
    "        batch_size_ = len(inputs)\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "#         pred_cln = predict_from_logits(model(inputs))\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        _, pred_cln = torch.max(outputs, 1)\n",
    "        \n",
    "        batch_corrects_test = torch.sum(pred_cln == labels.data).item()\n",
    "        \n",
    "        # running_corrects += batch_corrects\n",
    "        running_corrects_test += batch_corrects_test\n",
    "        \n",
    "    # final_acc = running_corrects / dataset_sizes[phase]\n",
    "    final_acc_test = running_corrects_test / dataset_sizes[phase]\n",
    "    \n",
    "    # print(\"Final Accuracy(original model): \",final_acc,final_acc_test)\n",
    "    time_elapsed = time.time() - since\n",
    "    print(\n",
    "        \"Testing completed in {:.0f}m {:.0f}s\".format(time_elapsed // 60, time_elapsed % 60)\n",
    "    )\n",
    "\n",
    "\n",
    "    print(\"Final Accuracy(original model): \",final_acc_test)\n",
    "    return final_acc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e6acea9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model,path):\n",
    "    print(path)\n",
    "    model.load_state_dict(torch.load(path))  \n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def classicalModel():\n",
    "    model_classical = torchvision.models.resnet152(pretrained=True)\n",
    "    \n",
    "    for param in model_classical.parameters():\n",
    "        param.requires_grad = False\n",
    "        \n",
    "    num_ftrs = model_classical.fc.in_features\n",
    "    model_classical.fc = ClassicalTransferLearningModel(num_ftrs)\n",
    "    model_classical = model_classical.to(device)\n",
    "#     print(model_classical)\n",
    "    return model_classical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2f0af868",
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = \"C:\\\\Users\\\\reekm\\\\Documents\\\\MachineLearningMathematics\\\\dogsCatModel.pth\"\n",
    "path =  \"dogsCatModel.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1bfafbdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reekm\\Documents\\MachineLearningMathematics\\dogsCatModel.pth\n",
      "Validation started:\n",
      "Testing completed in 7m 46s\n",
      "Final Accuracy(original model):  0.9885\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9885"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = classicalModel()\n",
    "model = load_model(model,path)\n",
    "test_acc = test_model(model)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a107dcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
